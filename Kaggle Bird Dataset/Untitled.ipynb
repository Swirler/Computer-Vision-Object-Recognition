{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Object recognition and computer vision 2018/2019\n",
    "\n",
    "### Assignment 3: Image classification \n",
    "\n",
    "#### Requirements\n",
    "1. Install PyTorch from http://pytorch.org\n",
    "\n",
    "2. Run the following command to install additional dependencies\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### Dataset\n",
    "We will be using a dataset containing 200 different classes of birds adapted from the [CUB-200-2011 dataset](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html).\n",
    "The training/validation/test images used for this model can be downloaded from [here](https://www.di.ens.fr/willow/teaching/recvis18/assignment3/bird_dataset.zip). The test image labels are not provided.\n",
    "\n",
    "#### Training and validating the model\n",
    "For the model, we used two pretrained models (ResNet152 and InceptionV3) to extract two features vectors. A classifier is added to classify the images using the stacked extracted features. See `model.py` and the attached paper for more details.\n",
    "\n",
    "To train the model with default parameters, run the following command :\n",
    "\n",
    "```bash\n",
    "python main.py\n",
    "```\n",
    "\n",
    "By default :\n",
    "- The images are loaded and resized to 331x331 pixels and normalized to zero-mean and standard deviation of 1. See data.py for the `data_train_transforms`. In order to preserve the ratio of the images, a padding option is available by running the following command (this option is **disabled** by default) :\n",
    "\n",
    "```bash\n",
    "python main.py --pad\n",
    "```\n",
    "\n",
    "- The data is augmented by preprocessing the images using YoloV3 to detect birds and add cropped images centered on the birds. The outputed images are saved at `bird_dataset_output`. See model.py for the `YoloV3` code.\n",
    "To deactivate the detection process and train on the original training and test sets, run the following command :\n",
    "\n",
    "```bash\n",
    "python main.py --no-crop\n",
    "```\n",
    "\n",
    "An other option for training the model on the training and validation sets is available by running the following command (this option is **disabled** by default): \n",
    "\n",
    "```bash\n",
    "python main.py --merge\n",
    "```\n",
    "\n",
    "#### Evaluating the model on the test set\n",
    "\n",
    "As the model trains, model checkpoints are saved to files such as `model_x.pth` to the current working directory.\n",
    "You can take one of the checkpoints and run:\n",
    "\n",
    "```\n",
    "python evaluate.py --data [data_dir] --model [model_file]\n",
    "```\n",
    "\n",
    "That generates a file `kaggle.csv` that you can upload to the private kaggle competition website.\n",
    "\n",
    "By default, the cropped images (bird_dataset_ouput) are used as the default directory.\n",
    "\n",
    "\n",
    "#### Acknowledgments\n",
    "Adapted from Rob Fergus and Soumith Chintala https://github.com/soumith/traffic-sign-detection-homework.\n",
    "\n",
    "#### Credits\n",
    "https://github.com/eriklindernoren/PyTorch-YOLOv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
